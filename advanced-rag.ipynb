{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Advanced RAG pipeline\n",
    "\n",
    "In this example we're going to build an Advanced RAG pipeline that can answer questions about the weather in a specific city. The example is going to use a couple of different techniques to make the pipeline more robust and efficient.\n",
    "The techniques we're going to use are quite simple to use and can be applied to many different use cases. \n",
    "\n",
    "- Query Routing - Added flexibility to the pipeline by allowing it to dynamically select the right data source to answer the query.\n",
    "- Hypothetical Document Embeddings (HyDE) - Generate hypothetical documents to allow for a broader search of the answers\n",
    "- Reranking - Use a reranker to improve the quality the retrieved documents\n",
    "- Custom Weather Query Engine - Use a custom query engine that fetches the weather data from an external API to use as context \n",
    "\n",
    "The following is a overview of the pipeline we're going to build:\n",
    "\n",
    "![AdvancedRAGPipeline](./img/AdvancedRAGPipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-postprocessor-rankgpt-rerank llama-index-postprocessor-cohere-rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.prompts.default_prompt_selectors import \\\n",
    "    DEFAULT_TREE_SUMMARIZE_PROMPT_SEL\n",
    "from llama_index.core.query_engine import (RouterQueryEngine,\n",
    "                                           TransformQueryEngine)\n",
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "from llama_index.core.selectors import LLMMultiSelector\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "from util.helpers import create_and_save_wiki_md_files, get_wiki_pages\n",
    "from util.query_engines import VerboseHyDEQueryTransform, WeatherQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes.\n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following to a `.env` file in the root of the project if not already there.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=<YOUR_KEY_HERE>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom `WeatherQueryEngine` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_query_engine = WeatherQueryEngine(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define cities query engine\n",
    "\n",
    "We define a query engine using HyDE to transform the initial query and Cohere Rerank to rerank the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_pages = get_wiki_pages(\n",
    "    [\n",
    "        \"Aarhus\",\n",
    "        \"London\",\n",
    "        \"Paris\",\n",
    "        \"Berlin\",\n",
    "        \"Tokyo\",\n",
    "        \"Beijing\",\n",
    "        \"Moscow\",\n",
    "        \"Sydney\",\n",
    "    ]\n",
    ")\n",
    "create_and_save_wiki_md_files(cities_pages, path=\"./data/docs/cities/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cities_documents = SimpleDirectoryReader(\"./data/docs/cities\").load_data()\n",
    "\n",
    "cities_index = VectorStoreIndex.from_documents(cities_documents, show_progress=True)\n",
    "\n",
    "reranker = CohereRerank(api_key=COHERE_API_KEY, top_n=5, model=\"rerank-english-v3.0\")\n",
    "hyde = VerboseHyDEQueryTransform(include_original=True, verbose=True)\n",
    "cities_query_engine = TransformQueryEngine(\n",
    "    query_engine=cities_index.as_query_engine(\n",
    "        similarity_top_k=10, node_postprocessors=[reranker], verbose=True\n",
    "    ),\n",
    "    query_transform=hyde,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define `RouterQueryEngine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=weather_query_engine,\n",
    "    description=\"Useful for getting todays weather forecast for a given city\",\n",
    ")\n",
    "cities_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=cities_query_engine,\n",
    "    name=\"Cities Wiki Pages\",\n",
    "    description=\"Useful for getting information about cities\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4-turbo\")\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMMultiSelector.from_defaults(llm=llm),\n",
    "    llm=llm,\n",
    "    summarizer=TreeSummarize(\n",
    "        llm=llm, summary_template=DEFAULT_TREE_SUMMARIZE_PROMPT_SEL, verbose=True\n",
    "    ),\n",
    "    query_engine_tools=[\n",
    "        weather_tool,\n",
    "        cities_tool,\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_engine.aquery(\"At what time should I go running today in Paris?\")\n",
    "display(Markdown(f'{response}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_engine.aquery(\"What are the best sights to see in Aarhus?\")\n",
    "display(Markdown(f'{response}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_engine.aquery(\n",
    "    \"What are the best sights to see in Aarhus and at what time is it best to go there with regards to weather?\"\n",
    ")\n",
    "display(Markdown(f\"{response}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
