{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Routing\n",
    "\n",
    "Sometimes its not possible to have all information in a single data source. Maybe your pipeline should be able to handle many different queries, or maybe you have a lot of data and you want to split it into different sources to make it easier find the retrieve the right documents.\n",
    "\n",
    "Imagine that you have to be able to answer questions about the current weather, but you also want to be able to answer questions about geography. Or you want to be able to limit the search space to search for different categories of documents.\n",
    "\n",
    "In these cases you can use **Query routing** to dynamically select the right data source to answer the query or search use multiple data sources to answer the query. On way to achieve this is to use the decision making capabilities of LLMs to decide on the fly where to retrieve data from. Query routing is part of the **Pre-retrieval** phase of Advanced RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from util.helpers import get_wiki_pages, create_and_save_wiki_md_files\n",
    "from util.query_engines import WeatherQueryEngine\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from llama_index.core.query_engine import RouterQueryEngine, CustomQueryEngine\n",
    "from llama_index.core.selectors import LLMMultiSelector, LLMSingleSelector\n",
    "from llama_index.core.tools import FunctionTool , QueryEngineTool\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, PromptTemplate\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes.\n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following to a `.env` file in the root of the project if not already there.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=<YOUR_KEY_HERE>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with `RouterQueryEngine`\n",
    "\n",
    "In the following example we build a `RouterQueryEngine` that will decide on the fly which data source to use to answer the query. We will have two data sources: \n",
    "\n",
    "- **Weather data source** - Query engine that can answer questions using todays weather forecast\n",
    "- **Wiki pages for cities data source** - Query engine that can answer questions using wikipedia pages for cities\n",
    "\n",
    "The `RouterQueryEngine` will use a LLM to decide which data source to use to answer the query. We use the `LLMMultiSelector` to allow the LLM to select multiple datasources if it needs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom `WeatherQueryEngine` \n",
    "\n",
    "See implementation of `WeatherQueryEngine` in [query_engines.py](./util/query_engines.py#91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_query_engine = WeatherQueryEngine(llm=OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\"), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await weather_query_engine.aquery(\"What is the weather in New York?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define query engine for Wiki pages for cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_pages = get_wiki_pages(\n",
    "    [\n",
    "        \"Aarhus\",\n",
    "        \"London\",\n",
    "        \"Paris\",\n",
    "        \"Berlin\",\n",
    "        \"Tokyo\",\n",
    "        \"Beijing\",\n",
    "        \"Moscow\",\n",
    "        \"Sydney\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_save_wiki_md_files(cities_pages, path=\"./data/docs/cities/\")\n",
    "cities_documents = SimpleDirectoryReader(\"./data/docs/cities\").load_data()\n",
    "cities_index = VectorStoreIndex.from_documents(cities_documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define `RouterQueryEngine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=weather_query_engine,\n",
    "    description=\"Useful for getting todays weather forecast for a given city\",\n",
    ")\n",
    "cities_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=cities_index.as_query_engine(),\n",
    "    name=\"Cities Wiki Pages\",\n",
    "    description=\"Useful for getting information about cities\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4-turbo\")\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMMultiSelector.from_defaults(llm=llm),\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    query_engine_tools=[\n",
    "        weather_tool,\n",
    "        cities_tool,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the prompt used by the selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MULTI_SELECT_PROMPT_TMPL = (\n",
    "    \"Some choices are given below. It is provided in a numbered list (1 to {num_choices}), \"\n",
    "    \"where each item in the list corresponds to a summary.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_list}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Using only the choices above and not prior knowledge, return the top choices \"\n",
    "    \"(no more than {max_outputs}, but only select what is needed) that \"\n",
    "    \"are most relevant to the question: '{query_str}'\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_engine.aquery(\"At what time should I go running today in Aarhus?\")\n",
    "display(Markdown(f'{response}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_engine.aquery(\"What are the best sights to see in Aarhus?\")\n",
    "display(Markdown(f'{response}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_engine.aquery(\n",
    "    \"What are the best sights to see in Aarhus and at what time is it best to go there with regards to weather?\"\n",
    ")\n",
    "display(Markdown(f\"{response}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
