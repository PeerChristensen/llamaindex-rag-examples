{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e8ba18-41fb-4db2-a708-ee9138c290dd",
   "metadata": {},
   "source": [
    "# Basic RAG from existing index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f55ee0-e8b4-4f24-8ff1-6913db380c4a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ac3b4f-d5ce-4c0b-a3a7-ccd5e37e1a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import BaseSynthesizer\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c2f05-9231-4994-b26c-b6913e1a0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3c65a9-d214-44da-a8cc-2b8b94094b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-05-01-preview\", # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    api_type=\"azure\",\n",
    "    api_version=\"2024-05-01-preview\"\n",
    ")\n",
    "\n",
    "chroma_client_load = chromadb.PersistentClient(\n",
    "    path=\"./landsforsøg/chromadb\",\n",
    "    settings=Settings(allow_reset=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9c9ca2-7d39-4f90-ab03-cf02c71e38c9",
   "metadata": {},
   "source": [
    "## Load collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b6a74de-c528-4aa3-88bf-78a550ab681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_load = chroma_client_load.get_collection(name=\"landsforsoeg\", embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00279ca0-cecc-40fc-bfff-2dab69aa3045",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68f57092-5089-4d00-bec0-5d82269412e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    \"\"\"You are a helpful assistant that answers questions about the content of documents and provides detailed expert advice. \n",
    "    You must provide your answer in the Danish language.\n",
    "    If the answer contains multiple steps or points, provide the answer in a bullet format.\n",
    "    Below the answer, the source of the answer should be provided including file_name and page_label, which are stored as metadata.\n",
    "    ---------------------\n",
    "    {context}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query.\n",
    "    Query: {query}\n",
    "    Answer: \n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88a527-857a-4df5-910e-97e1959e2e7c",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f9ad004-7f57-40b6-b7a2-5eea58147b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"hvem udgiver landsforsøgene?\"\n",
    "#query = \"hvordan kan jeg bedst bekæmpe væselhale?\"\n",
    "query = \"hvordan vælger jeg den bedste vårbygsort?\"\n",
    "#query = \"hvad er reglerne for afstande ved etablering af husdyranlæg?\"\n",
    "#query = \"Beskriv MT-Klovvask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5d35517-ede2-4210-af4b-83b8f8772ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collection_load.query(query_texts=[query], n_results=5)\n",
    "context = result[\"documents\"][0]\n",
    "message = prompt.format(query=query, context=\"\\n\\n\".join(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cd27b04-28c5-46f7-a423-2af5be7838b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Vælg en vårbygsort, der giver et stort og stabilt udbytte i flere års forsøg. \n",
       "- Vælg en sort, der har lav modtagelighed over for sygdommene meldug, bygrust, skoldplet og bygbladplet. \n",
       "- Vælg en sort, der har resistens mod havrecystenematoder. \n",
       "- Vælg en sort, der har en god stråstivhed, så der ikke er behov for vækstregulering. \n",
       "- Vælg en sort, der har en svag tendens til nedknækning af aks og strå. \n",
       "- Ved dyrkning af vårbyg til malt, bør der altid vælges en maltbygsort, der er accepteret af handelspartneren.\n",
       "\n",
       "Kilde: 76 VÅRBYG SORTERVÅRBYG, 87 VÅRBYG SORTER, VÅRBYG, 83 VÅRBYG UKRUDT, 205 ØKOLOGISK DYRKNING VÅRBYG – SORTER OG DYRKNING, \n",
       "93 VÅRBYG SORTER"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = openai_client.chat.completions.create(\n",
    "    #messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    model=\"gpt4\",\n",
    "    messages=[\n",
    "        {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n",
    "        for m in [{\"role\": \"user\", \"content\": message}]#st.session_state.messages\n",
    "    ],\n",
    "    stream=True)\n",
    "\n",
    "output = \"\"\n",
    "for chunk in stream:\n",
    "    if chunk.choices:  # Check if the list is not empty\n",
    "        output += chunk.choices[0].delta.content or \"\"\n",
    "    display(Markdown(f\"{output}\"), clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebad8795-5723-458e-99a8-b588e62a1b38",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AzureOpenAI.__init__() got an unexpected keyword argument 'deployment_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceSplitter\n\u001b[1;32m      5\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m ChromaVectorStore(chroma_collection\u001b[38;5;241m=\u001b[39mcollection_load)\n\u001b[0;32m----> 7\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mAzureOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#model=\"gpt-4\",\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_VERSION\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAZURE_OPENAI_ENDPOINT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# You need to deploy your own embedding model as well as your own chat completion model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m embedding \u001b[38;5;241m=\u001b[39m AzureOpenAIEmbedding(\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     deployment_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_ENDPOINT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: AzureOpenAI.__init__() got an unexpected keyword argument 'deployment_name'"
     ]
    }
   ],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection_load)\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=\"gpt4\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embedding = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# Define the ingestion pipeline to add documents to vector store\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=20),\n",
    "        embedding,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "# Create index with the vector store and using the embedding model\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7b972-1e58-4f6d-8ba3-79c455f7988d",
   "metadata": {},
   "source": [
    "## Query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95b3db36-01d1-4b9f-a2d6-90e0b8ee7b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(response) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mKontekst:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m context_str\n\u001b[1;32m     21\u001b[0m synthesizer \u001b[38;5;241m=\u001b[39m get_response_synthesizer(response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m RAGQueryEngine(\n\u001b[0;32m---> 23\u001b[0m     retriever\u001b[38;5;241m=\u001b[39m\u001b[43mindex\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(),\n\u001b[1;32m     24\u001b[0m     response_synthesizer\u001b[38;5;241m=\u001b[39msynthesizer,\n\u001b[1;32m     25\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     26\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     27\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "class RAGQueryEngine(CustomQueryEngine):\n",
    "    \"\"\"RAG String Query Engine.\"\"\"\n",
    "\n",
    "    retriever: BaseRetriever\n",
    "    response_synthesizer: BaseSynthesizer\n",
    "    llm: AzureOpenAI\n",
    "    prompt: PromptTemplate\n",
    "\n",
    "    def custom_query(self, query_str: str):\n",
    "        nodes = self.retriever.retrieve(query_str)\n",
    "        context_str = \"\\n\\n\".join([n.node.get_content(metadata_mode=\"all\") for n in nodes])\n",
    "        #context = qa_prompt.format(\n",
    "        #    context_str=context_str, query_str=query_str)\n",
    "        response = self.llm.complete(\n",
    "            qprompt.format(context_str=context_str, query_str=query_str)\n",
    "        )\n",
    "                    \n",
    "        return str(response) + \"\\n\\n-------------------------\\n\\nKontekst:\\n\\n\" + context_str\n",
    "\n",
    "\n",
    "synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "query_engine = RAGQueryEngine(\n",
    "    retriever=index.as_retriever(),\n",
    "    response_synthesizer=synthesizer,\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2694b8c-4cf0-4517-8a51-7dea1cdd7b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
