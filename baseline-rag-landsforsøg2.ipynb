{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af80224-ed68-497e-8cfd-29f3a0c5f31b",
   "metadata": {},
   "source": [
    "# Baseline RAG - landsforsøg 2022 pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45b867-f920-44a8-ac15-7f8f8961db93",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ba3518b-d172-4507-bfc4-35347ebef4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb==0.4.14\n",
      "  Downloading chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (2.7.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.30.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (4.12.2)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb==0.4.14)\n",
      "  Downloading pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (1.18.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (1.64.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (1.26.4)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (0.0.4)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (0.27.0)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (3.1.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (5.10.0)\n",
      "Requirement already satisfied: orjson>=3.2.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (3.10.3)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (2.1.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (24.3.25)\n",
      "Requirement already satisfied: packaging in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (24.0)\n",
      "Requirement already satisfied: protobuf in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (4.25.3)\n",
      "Requirement already satisfied: sympy in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (1.12.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.4.14) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.4.14) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.4.14) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.4.14) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.14) (2024.6.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb==0.4.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb==0.4.14) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from requests>=2.28->chromadb==0.4.14) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from requests>=2.28->chromadb==0.4.14) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from requests>=2.28->chromadb==0.4.14) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb==0.4.14) (0.23.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.4.14) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.4.14) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.4.14) (13.7.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (1.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (6.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (12.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb==0.4.14) (2.6.1)\n",
      "Requirement already satisfied: anyio in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb==0.4.14) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb==0.4.14) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb==0.4.14) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.14) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.14) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb==0.4.14) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.14) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.14) (2.18.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.14) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.14) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.14) (0.1.2)\n",
      "Downloading chromadb-0.4.14-py3-none-any.whl (448 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pulsar-client, chromadb\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 0.5.0\n",
      "    Uninstalling chromadb-0.5.0:\n",
      "      Successfully uninstalled chromadb-0.5.0\n",
      "Successfully installed chromadb-0.4.14 pulsar-client-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install llama-index-readers-smart-pdf-loader\n",
    "#%pip install llama-parse\n",
    "#%pip install llmsherp\n",
    "#%pip install --upgrade chromadb==0.4.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b531daa-2211-4c98-b8ff-7d792addcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb import Settings\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core import PromptTemplate, SimpleDirectoryReader\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llmsherpa.readers import LayoutPDFReader\n",
    "from llama_index.readers.smart_pdf_loader import SmartPDFLoader\n",
    "\n",
    "#from llama_index.llms.azure_openai import AzureOpenAI\n",
    "#rom llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "\n",
    "import importlib\n",
    "import util\n",
    "\n",
    "#importlib.reload(util.helpers)\n",
    "from util.helpers import create_and_save_md_files, get_malazan_pages, get_office_pages, get_friends_pages, get_theoffice_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04907f9-c54f-466e-8a58-94fcbc67e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56782cbc-ee60-4c71-b1a1-2b52bbcf3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB Vector Store\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"./landsforsøg/chromadb\", settings=Settings(allow_reset=True))\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key=OPENAI_API_KEY,  \n",
    "    api_version=\"2024-05-01-preview\", # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    api_type=\"azure\",\n",
    "    api_version=\"2024-05-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd079c-e39d-400a-b7ed-f66c35bef4c2",
   "metadata": {},
   "source": [
    "## Load document(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e7ff1-87a8-49a8-8540-60b410a825c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attempt 1: LayoutPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdf2929-b84e-4a61-81a9-74e4b2d581e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "pdf = \"landsforsøg/planter_landsforsogene_2022.pdf\"\n",
    "doc = pdf_reader.read_pdf(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1839be-eed7-41f8-b4d4-33fea177f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5086"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.chunks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92fa2f7-f07f-496a-b733-5bc1403b52f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llmsherpa.readers.layout_reader.Paragraph at 0x145c69e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.chunks()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6da8d-8050-49c1-84a3-4b81bd07b37f",
   "metadata": {},
   "source": [
    "Using VectorStoreIndex below yields an Authentication error\n",
    "\n",
    "AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: e611f630********************6e3d. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47530215-1089-4d26-be99-d4c22c86656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\n",
    "\n",
    "index = VectorStoreIndex([])\n",
    "for chunk in doc.chunks():\n",
    "    index.insert(Document(text=chunk.to_context_text(), extra_info={}))\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Let's run one query\n",
    "response = query_engine.query(\"list all the tasks that work with bart\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99819a5-445e-4c6d-b63f-d1d260f61b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(doc)\n",
    "#TypeError: 'Document' object is not iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241c12d-bc2a-4d56-bda4-8b8c4abcf00a",
   "metadata": {},
   "source": [
    "### Attempt 2: SmartPDFLoader\n",
    "https://llamahub.ai/l/readers/llama-index-readers-smart-pdf-loader?from="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb79d87-5c50-42fa-a499-3fcce35a61b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landsforsøg/documents/Husdyrbrugloven.pdf\n"
     ]
    }
   ],
   "source": [
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_loader = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\n",
    "#pdf = \"landsforsøg/planter_landsforsogene_2022.pdf\"\n",
    "#documents = pdf_loader.load_data(pdf)\n",
    "\n",
    "documents = []\n",
    "for file in os.listdir(\"landsforsøg/documents\"):\n",
    "    filepath = f\"landsforsøg/documents/{file}\"\n",
    "    if \"Husdyrbrugloven\" in filepath:\n",
    "        print(filepath)\n",
    "        doc = pdf_loader.load_data(filepath, extra_info={\"doc_name\": filepath})\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2880e-9e2d-429f-9ad8-96ab7731f9cb",
   "metadata": {},
   "source": [
    "### Attempt 3: SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3348d08c-73f9-4e36-8908-85339e9e3e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 662 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "reader = SimpleDirectoryReader(\"./landsforsøg/documents/\")\n",
    "#/Husdyrbrugloven.pdf\",\"landsforsøg/documents/FT-73_Klovvaskere_web.pdf\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d52d89-be8d-4bcf-8084-01cc57a78f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#authentication error\n",
    "#index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0129421-c1ec-4d34-8b63-0450a5217fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_data = []\n",
    "for idx, doc in enumerate(documents):\n",
    "    embedding = openai_client.embeddings.create(\n",
    "        input=doc.text, model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    document_data.append({\n",
    "        \"id\": f\"{doc.id_}-{idx}\",\n",
    "        \"text\": doc.text,\n",
    "        \"metadata\":doc.metadata,\n",
    "        \"embedding\": embedding.data[0].embedding\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "773adae7-ff45-437c-b01f-73c6e51c11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc[\"text\"] for doc in document_data]\n",
    "embeddings = [doc[\"embedding\"] for doc in document_data]\n",
    "metadatas = [doc[\"metadata\"] for doc in document_data]\n",
    "ids = [doc[\"id\"] for doc in document_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a676d03-70c6-4dc4-9a40-f9eb4484dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.reset()\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"landsforsoeg\", metadata={\"hnsw:space\": \"cosine\"}, embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9da39b28-f618-42b3-9e97-8772e58a439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=documents,\n",
    "    metadatas=metadata,\n",
    "    ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36aaf2-49cf-4bd0-b40c-7301da0a225b",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f4764fa-44f7-460e-bf9e-da73ac42cef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhvordan kan jeg bedst bekæmpe væselhale?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m context \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#display(Markdown(f\"------------\\n\\n{\"\\n\\n------------\\n\\n\".join(context)}\"))\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages/chromadb/api/models/Collection.py:211\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide embeddings or a function to compute them\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# We know query texts is not None at this point, cast for the typechecker\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDocument\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     where \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages/chromadb/utils/embedding_functions.py:133\u001b[0m, in \u001b[0;36mOpenAIEmbeddingFunction.__call__\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    130\u001b[0m texts \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Call the OpenAI Embedding API\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_name\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Sort resulting embeddings by index\u001b[39;00m\n\u001b[1;32m    136\u001b[0m sorted_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(embeddings, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m e: e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "query = \"hvordan kan jeg bedst bekæmpe væselhale?\"\n",
    "\n",
    "result = collection.query(query_texts=[query], n_results=5)\n",
    "context = result[\"documents\"][0]\n",
    "#display(Markdown(f\"------------\\n\\n{\"\\n\\n------------\\n\\n\".join(context)}\"))\n",
    "\n",
    "formatted_text = \"\\n\\n------------\\n\\n\".join(context)\n",
    "\n",
    "# Display the formatted markdown\n",
    "display(Markdown(f\"{formatted_text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36c382-25a7-4c4b-a851-7e150551f409",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d498fa2a-3bba-4218-83da-35d9c218cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"hvordan kan jeg bedst bekæmpe væselhale?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb1ac5d-1204-4fb3-a45c-ba5e6f3804e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MARKFRØ > Rødsvingel > Bekæmpelse af væselhale i rødsvingel\n",
       "I 2023 er der i samarbejde med DLF videreført en forsøgsserie, som skal belyse mulighederne for bekæmpelse af væselhale i rødsvingel om efteråret.\n",
       "Væselhale skal bekæmpes så tidligt som muligt efter fremspiring.\n",
       "Problemet er, at den spirer over en meget lang periode, og derfor er det vanskeligt at dække af for fremspiring.\n",
       "\n",
       "------------\n",
       "\n",
       "Svampesygdomme > FOTO: SOFIE HÆSTRUP OLESEN, LANDBONORD\n",
       "Optimalt tidspunkt for bekæmpelse af væselhale med Boxer og Mateno Duo.\n",
       "\n",
       "------------\n",
       "\n",
       "Ukrudt > Bekæmpelse af væselhale om efteråret\n",
       "Det understreger, at kemisk bekæmpelse af væselhale ikke kan stå alene, men at bestanden skal bringes ned på et niveau, hvor de tilbageværende væselhale efter kemisk bekæmpelse er få og uden betydning for fortsat opformering og spredning.\n",
       "\n",
       "------------\n",
       "\n",
       "Svampesygdomme > FOTO: SOFIE HÆSTRUP OLESEN, LANDBONORD\n",
       "TABEL 18.\n",
       "Bekæmpelse af væselhale i vinterhvede om efter- året.\n",
       "(E16) Vinterhvede Stadie Væselhale Kemi og udbring- ning, kr.\n",
       "pr.\n",
       "ha Oktober November Antal planter pr.\n",
       "m2 Antal planter pr.\n",
       "m2 Procent effekt 2021-22, 3 forsøg\n",
       "\n",
       "------------\n",
       "\n",
       "Ukrudt > Bekæmpelse af væselhale om efteråret\n",
       "Der er udført tre forsøg i vinterhvede med bekæmpelse af væselhale med forskellige strategier med Boxer, Ma- teno Duo og Atlantis OD i henholdsvis stadie 10-11 og stadie 12.\n",
       "Behandlingerne ses i tabel 18.\n",
       "Forsøgene er udført på arealer med en meget stor be- stand af væselhale, i gennemsnit ca.\n",
       "600 planter pr.\n",
       "m2 ved optælling i oktober.\n",
       "Den tidlige sprøjtning i stadie 10-11 er udført fra 6 til 14 dage efter såning, som i gen- nemsnit har været midt i september.\n",
       "Anden sprøjtning i Forsøgsled 2 og 6 viser, at der er opnået samme effekt- niveau af 1,5 l Boxer pr.\n",
       "ha og 0,7 l Mateno Duo pr.\n",
       "ha.\n",
       "I forsøgsled 3 til 5 er forskellige blandingsforhold mel- lem Boxer og Mateno Duo afprøvet, hvilket samlet er en højere indsats.\n",
       "Effekten er dermed også lidt bedre.\n",
       "Re- sultatet viser også i disse forsøgsled, at der har været et ligeværdigt bidrag fra begge midler."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = collection.query(query_texts=[query], n_results=5)\n",
    "context = result[\"documents\"][0]\n",
    "#display(Markdown(f\"------------\\n\\n{\"\\n\\n------------\\n\\n\".join(context)}\"))\n",
    "\n",
    "formatted_text = \"\\n\\n------------\\n\\n\".join(context)\n",
    "\n",
    "# Display the formatted markdown\n",
    "display(Markdown(f\"{formatted_text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d72d4-9bc5-4841-8d9c-ac607e7c754b",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f57f936b-889a-4a9b-8e76-a588a0bfc9f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhvordan kan jeg bedst bekæmpe væselhale?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant that answers questions about landsforsøgene using provided context. You must provide your answer in the Danish language.\u001b[39m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{query}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m message \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat(query\u001b[38;5;241m=\u001b[39mquery, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mcontext\u001b[49m))\n\u001b[1;32m     16\u001b[0m display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'context' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = PromptTemplate(\"\"\"You are a helpful assistant that answers questions about landsforsøgene using provided context. You must provide your answer in the Danish language.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Context: \n",
    "\n",
    "-----------------------------------\n",
    "{context}\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "\"\"\")\n",
    "message = prompt.format(query=query, context=\"\\n\\n\".join(context))\n",
    "display(Markdown(f\"{message}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f15b71f-dbeb-4138-9235-db6c453ffaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Skadedyrsbekæmpelse: Hvis dit hjem er inficeret med væselhale, kan du overveje at ansætte en skadedyrsbekæmpelse specialist, der har værktøjer og erfaring med at eliminere denne type skadedyr.\n",
       "\n",
       "2. Reducér fugt: Væselhale trives i fugtige omgivelser. Du kan minimere fugt ved at reparere lækager, anvende fugtighedsabsorberende produkter og holde dit hjem godt ventileret.\n",
       "\n",
       "3. Støvsug regelmæssigt: Væselhale har tendens til at gemme sig i støvede, mørke områder. Støvsugning kan hjælpe med at fjerne disse skjulesteder og eventuelle æg, de må have lagt.\n",
       "\n",
       "4. Anvend insekticider: Du kan også bruge insekticider designet til at bekæmpe væselhale. Det er vigtigt at følge instruktionerne omhyggeligt for at undgå at skade dit hjem eller din sundhed.\n",
       "\n",
       "5. Benyt fælder: Giftfri limfælder kan være effektive til at fange væselhale. Fælderne kan placere på steder, hvor du har observeret væselhale, såsom køkkenet, badeværelset eller kælderen.\n",
       "\n",
       "Husk at det altid er bedst at få professionel hjælp, hvis du har problemer med skadedyr i dit hjem. En professionel skadedyrsspecialist kan give en mere permanent løsning på problemet."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"hvordan kan jeg bedst bekæmpe væselhale?\"\n",
    "\n",
    "stream = openai_client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    model=\"gpt4\",\n",
    "    stream=True)\n",
    "\n",
    "output = \"\"\n",
    "for chunk in stream:\n",
    "    if chunk.choices:  # Check if the list is not empty\n",
    "        output += chunk.choices[0].delta.content or \"\"\n",
    "    display(Markdown(f\"{output}\"), clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c16e9-8df3-4558-a3bd-303274ca657c",
   "metadata": {},
   "source": [
    "## Normal RAG example with llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba467d07-258a-4db8-a02d-68fae55e848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from chromadb import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ChromaDB Vector Store\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"./landsforsøg/data/baseline-rag/chromadb\", settings=Settings(allow_reset=True))\n",
    "chroma_client.reset()\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"landsforsoeg\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=\"gpt4\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embedding = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# Define the ingestion pipeline to add documents to vector store\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=20),\n",
    "        embedding,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "# Create index with the vector store and using the embedding model\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fb9e4b-a9ad-4da6-aaa5-82a17402c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 662 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Fetch documents\n",
    "documents = SimpleDirectoryReader('./landsforsøg').load_data()\n",
    "\n",
    "# Run pipeline\n",
    "pipeline.run(documents=documents)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f05231da-1fb9-48f8-b935-859d19e02140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import BaseSynthesizer\n",
    "\n",
    "    \n",
    "qa_prompt = PromptTemplate(\n",
    "    \"\"\"You are a helpful assistant that answers questions about the content of documents and provides detailed expert advice. \n",
    "    You must provide your answer in the Danish language.\n",
    "    If the answer contains multiple steps or points, provide the answer in a bullet format.\n",
    "    Below the answer, the source of the answer should be provided including file name and page number.\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query.\n",
    "    Query: {query_str}\n",
    "    Answer: \n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "class RAGQueryEngine(CustomQueryEngine):\n",
    "    \"\"\"RAG String Query Engine.\"\"\"\n",
    "\n",
    "    retriever: BaseRetriever\n",
    "    response_synthesizer: BaseSynthesizer\n",
    "    llm: OpenAI\n",
    "    qa_prompt: PromptTemplate\n",
    "\n",
    "    def custom_query(self, query_str: str):\n",
    "        nodes = self.retriever.retrieve(query_str)\n",
    "        context_str = \"\\n\\n\".join([n.node.get_content(metadata_mode=\"all\") for n in nodes])\n",
    "        #context = qa_prompt.format(\n",
    "        #    context_str=context_str, query_str=query_str)\n",
    "        response = self.llm.complete(\n",
    "            qa_prompt.format(context_str=context_str, query_str=query_str)\n",
    "        )\n",
    "                    \n",
    "        return str(response) + \"\\n\\n-------------------------\\n\\nKontekst:\\n\\n\" + context_str\n",
    "\n",
    "\n",
    "synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "query_engine = RAGQueryEngine(\n",
    "    retriever=index.as_retriever(),\n",
    "    response_synthesizer=synthesizer,\n",
    "    llm=llm,\n",
    "    qa_prompt=qa_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96f193f2-2f12-4b69-b306-f2fb3bc01b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "For at vælge den bedste vårbygsort, skal du overveje følgende faktorer:\n",
       "\n",
       "- Vælg en sort, der har givet et stort og stabilt udbytte i flere års forsøg.\n",
       "- Vælg en sort, der har lav modtagelighed over for sygdomme, i prioriteret rækkefølge: meldug, bygrust, skoldplet og bygbladplet.\n",
       "- Vælg en sort, der har resistens mod havrecystenematoder.\n",
       "- Vælg en sort, der har en god stråstivhed, så der ikke er behov for vækstregulering.\n",
       "- Vælg en sort, der har en svag tendens til nedknækning af aks og strå.\n",
       "- Hvis du dyrker vårbyg til malt, skal du altid vælge en maltbygsort, der er accepteret af handelspartneren.\n",
       "\n",
       "Kilde: planter_landsforsogene_2023.pdf, side 77 og planter_landsforsogene_2022.pdf, side 89.\n",
       "\n",
       "-------------------------\n",
       "\n",
       "Kontekst:\n",
       "\n",
       "page_label: 77\n",
       "file_name: planter_landsforsogene_2023.pdf\n",
       "file_path: /Users/peerchristensen/Desktop/Projects/advanced-rag-examples/landsforsøg/planter_landsforsogene_2023.pdf\n",
       "file_type: application/pdf\n",
       "file_size: 47095474\n",
       "creation_date: 2024-06-08\n",
       "last_modified_date: 2024-06-08\n",
       "\n",
       "Der var mange grønskud i vårbyg i 2023. Her er det en prøve fra \n",
       "et forsøg med et vandindhold på over 30 procent.FOTO: LEIF HAGELSKJÆR, SEGES INNOVATION\n",
       "STRATEGI\n",
       "Vælg en vårbygsort, der:\n",
       " >har givet et stort og stabilt udbytte i flere års for -\n",
       "søg\n",
       " >har lav modtagelighed over for sygdommene (i \n",
       "prioriteret rækkefølge):\n",
       " – meldug\n",
       " – bygrust\n",
       " – skoldplet og bygbladplet\n",
       " >har resistens mod havrecystenematoder\n",
       " >har en god stråstivhed, så der ikke er behov for \n",
       "vækstregulering\n",
       " >har en svag tendens til nedknækning af aks og \n",
       "strå.\n",
       "Ved dyrkning af vårbyg til malt bør der altid vælges \n",
       "en maltbygsort, der er accepteret af handelspart -\n",
       "neren.\n",
       "\n",
       "page_label: 89\n",
       "file_name: planter_landsforsogene_2022.pdf\n",
       "file_path: /Users/peerchristensen/Desktop/Projects/advanced-rag-examples/landsforsøg/planter_landsforsogene_2022.pdf\n",
       "file_type: application/pdf\n",
       "file_size: 53911931\n",
       "creation_date: 2024-06-07\n",
       "last_modified_date: 2024-06-07\n",
       "\n",
       "17. maj. Forsøget er sået d. 21. marts.FOTO: LEIF HAGELSKJÆR, SEGES INNOVATION\n",
       "STRATEGI\n",
       "Vælg en vårbygsort, der:\n",
       " >har givet et stort og stabilt udbytte i flere års for -\n",
       "søg\n",
       " >har lav modtagelighed over for sygdommene (i \n",
       "prioriteret rækkefølge):\n",
       "– meldug\n",
       "– bygrust\n",
       "– skoldplet og bygbladplet\n",
       " >har resistens mod havrecystenematoder\n",
       " >har en god stråstivhed, så der ikke er behov for \n",
       "vækstregulering\n",
       " >har en svag tendens til nedknækning af aks og \n",
       "strå.\n",
       "Ved dyrkning af vårbyg til malt bør der altid vælges \n",
       "en maltbygsort, der er accepteret af handelspart -\n",
       "neren."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "#query = \"hvem udgiver landsforsøgene?\"\n",
    "#query = \"hvordan kan jeg bedst bekæmpe væselhale?\"\n",
    "query = \"hvordan vælger jeg den bedste vårbygsort?\"\n",
    "#query = \"hvad er reglerne for afstande ved etablering af husdyranlæg?\"\n",
    "#query = \"Beskriv MT-Klovvask\"\n",
    "response = query_engine.query(query)\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f4edc-00d2-4228-a34b-8296f30b0b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
