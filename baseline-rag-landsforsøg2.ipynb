{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af80224-ed68-497e-8cfd-29f3a0c5f31b",
   "metadata": {},
   "source": [
    "# Baseline RAG - landsforsÃ¸g 2022 pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45b867-f920-44a8-ac15-7f8f8961db93",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ba3518b-d172-4507-bfc4-35347ebef4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb==0.4.14\n",
      "  Downloading chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (2.7.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.30.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (4.12.2)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb==0.4.14)\n",
      "  Downloading pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (1.18.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (1.64.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from chromadb==0.4.14) (1.26.4)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (0.0.4)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (0.27.0)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (3.1.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (5.10.0)\n",
      "Requirement already satisfied: orjson>=3.2.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (3.10.3)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.4.14) (2.1.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (24.3.25)\n",
      "Requirement already satisfied: packaging in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (24.0)\n",
      "Requirement already satisfied: protobuf in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (4.25.3)\n",
      "Requirement already satisfied: sympy in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (1.12.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.4.14) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.4.14) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.4.14) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.4.14) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.14) (2024.6.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb==0.4.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb==0.4.14) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from requests>=2.28->chromadb==0.4.14) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from requests>=2.28->chromadb==0.4.14) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from requests>=2.28->chromadb==0.4.14) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb==0.4.14) (0.23.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.4.14) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.4.14) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.4.14) (13.7.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (1.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (6.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.14) (12.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb==0.4.14) (2.6.1)\n",
      "Requirement already satisfied: anyio in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb==0.4.14) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb==0.4.14) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb==0.4.14) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.14) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.14) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb==0.4.14) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.14) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.14) (2.18.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.14) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.14) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/peerchristensen/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.14) (0.1.2)\n",
      "Downloading chromadb-0.4.14-py3-none-any.whl (448 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pulsar-client, chromadb\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 0.5.0\n",
      "    Uninstalling chromadb-0.5.0:\n",
      "      Successfully uninstalled chromadb-0.5.0\n",
      "Successfully installed chromadb-0.4.14 pulsar-client-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install llama-index-readers-smart-pdf-loader\n",
    "#%pip install llama-parse\n",
    "#%pip install llmsherp\n",
    "#%pip install --upgrade chromadb==0.4.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b531daa-2211-4c98-b8ff-7d792addcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb import Settings\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core import PromptTemplate, SimpleDirectoryReader\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llmsherpa.readers import LayoutPDFReader\n",
    "from llama_index.readers.smart_pdf_loader import SmartPDFLoader\n",
    "\n",
    "#from llama_index.llms.azure_openai import AzureOpenAI\n",
    "#rom llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "\n",
    "import importlib\n",
    "import util\n",
    "\n",
    "#importlib.reload(util.helpers)\n",
    "from util.helpers import create_and_save_md_files, get_malazan_pages, get_office_pages, get_friends_pages, get_theoffice_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04907f9-c54f-466e-8a58-94fcbc67e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56782cbc-ee60-4c71-b1a1-2b52bbcf3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB Vector Store\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"./landsforsÃ¸g/chromadb\", settings=Settings(allow_reset=True))\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key=OPENAI_API_KEY,  \n",
    "    api_version=\"2024-05-01-preview\", # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    api_type=\"azure\",\n",
    "    api_version=\"2024-05-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd079c-e39d-400a-b7ed-f66c35bef4c2",
   "metadata": {},
   "source": [
    "## Load document(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e7ff1-87a8-49a8-8540-60b410a825c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attempt 1: LayoutPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdf2929-b84e-4a61-81a9-74e4b2d581e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "pdf = \"landsforsÃ¸g/planter_landsforsogene_2022.pdf\"\n",
    "doc = pdf_reader.read_pdf(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1839be-eed7-41f8-b4d4-33fea177f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5086"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.chunks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92fa2f7-f07f-496a-b733-5bc1403b52f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llmsherpa.readers.layout_reader.Paragraph at 0x145c69e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.chunks()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6da8d-8050-49c1-84a3-4b81bd07b37f",
   "metadata": {},
   "source": [
    "Using VectorStoreIndex below yields an Authentication error\n",
    "\n",
    "AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: e611f630********************6e3d. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47530215-1089-4d26-be99-d4c22c86656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\n",
    "\n",
    "index = VectorStoreIndex([])\n",
    "for chunk in doc.chunks():\n",
    "    index.insert(Document(text=chunk.to_context_text(), extra_info={}))\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Let's run one query\n",
    "response = query_engine.query(\"list all the tasks that work with bart\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99819a5-445e-4c6d-b63f-d1d260f61b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(doc)\n",
    "#TypeError: 'Document' object is not iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241c12d-bc2a-4d56-bda4-8b8c4abcf00a",
   "metadata": {},
   "source": [
    "### Attempt 2: SmartPDFLoader\n",
    "https://llamahub.ai/l/readers/llama-index-readers-smart-pdf-loader?from="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb79d87-5c50-42fa-a499-3fcce35a61b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landsforsÃ¸g/documents/Husdyrbrugloven.pdf\n"
     ]
    }
   ],
   "source": [
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_loader = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\n",
    "#pdf = \"landsforsÃ¸g/planter_landsforsogene_2022.pdf\"\n",
    "#documents = pdf_loader.load_data(pdf)\n",
    "\n",
    "documents = []\n",
    "for file in os.listdir(\"landsforsÃ¸g/documents\"):\n",
    "    filepath = f\"landsforsÃ¸g/documents/{file}\"\n",
    "    if \"Husdyrbrugloven\" in filepath:\n",
    "        print(filepath)\n",
    "        doc = pdf_loader.load_data(filepath, extra_info={\"doc_name\": filepath})\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2880e-9e2d-429f-9ad8-96ab7731f9cb",
   "metadata": {},
   "source": [
    "### Attempt 3: SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3348d08c-73f9-4e36-8908-85339e9e3e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 662 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "reader = SimpleDirectoryReader(\"./landsforsÃ¸g/documents/\")\n",
    "#/Husdyrbrugloven.pdf\",\"landsforsÃ¸g/documents/FT-73_Klovvaskere_web.pdf\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d52d89-be8d-4bcf-8084-01cc57a78f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#authentication error\n",
    "#index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0129421-c1ec-4d34-8b63-0450a5217fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_data = []\n",
    "for idx, doc in enumerate(documents):\n",
    "    embedding = openai_client.embeddings.create(\n",
    "        input=doc.text, model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    document_data.append({\n",
    "        \"id\": f\"{doc.id_}-{idx}\",\n",
    "        \"text\": doc.text,\n",
    "        \"metadata\":doc.metadata,\n",
    "        \"embedding\": embedding.data[0].embedding\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "773adae7-ff45-437c-b01f-73c6e51c11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc[\"text\"] for doc in document_data]\n",
    "embeddings = [doc[\"embedding\"] for doc in document_data]\n",
    "metadatas = [doc[\"metadata\"] for doc in document_data]\n",
    "ids = [doc[\"id\"] for doc in document_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a676d03-70c6-4dc4-9a40-f9eb4484dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.reset()\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"landsforsoeg\", metadata={\"hnsw:space\": \"cosine\"}, embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9da39b28-f618-42b3-9e97-8772e58a439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=documents,\n",
    "    metadatas=metadata,\n",
    "    ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36aaf2-49cf-4bd0-b40c-7301da0a225b",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f4764fa-44f7-460e-bf9e-da73ac42cef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhvordan kan jeg bedst bekÃ¦mpe vÃ¦selhale?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m context \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#display(Markdown(f\"------------\\n\\n{\"\\n\\n------------\\n\\n\".join(context)}\"))\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages/chromadb/api/models/Collection.py:211\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide embeddings or a function to compute them\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# We know query texts is not None at this point, cast for the typechecker\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDocument\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     where \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages/chromadb/utils/embedding_functions.py:133\u001b[0m, in \u001b[0;36mOpenAIEmbeddingFunction.__call__\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    130\u001b[0m texts \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Call the OpenAI Embedding API\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_name\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Sort resulting embeddings by index\u001b[39;00m\n\u001b[1;32m    136\u001b[0m sorted_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(embeddings, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m e: e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/advanced-rag-env/lib/python3.11/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "query = \"hvordan kan jeg bedst bekÃ¦mpe vÃ¦selhale?\"\n",
    "\n",
    "result = collection.query(query_texts=[query], n_results=5)\n",
    "context = result[\"documents\"][0]\n",
    "#display(Markdown(f\"------------\\n\\n{\"\\n\\n------------\\n\\n\".join(context)}\"))\n",
    "\n",
    "formatted_text = \"\\n\\n------------\\n\\n\".join(context)\n",
    "\n",
    "# Display the formatted markdown\n",
    "display(Markdown(f\"{formatted_text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36c382-25a7-4c4b-a851-7e150551f409",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d498fa2a-3bba-4218-83da-35d9c218cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"hvordan kan jeg bedst bekÃ¦mpe vÃ¦selhale?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb1ac5d-1204-4fb3-a45c-ba5e6f3804e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MARKFRÃ > RÃ¸dsvingel > BekÃ¦mpelse af vÃ¦selhale i rÃ¸dsvingel\n",
       "I 2023 er der i samarbejde med DLF viderefÃ¸rt en forsÃ¸gsserie, som skal belyse mulighederne for bekÃ¦mpelse af vÃ¦selhale i rÃ¸dsvingel om efterÃ¥ret.\n",
       "VÃ¦selhale skal bekÃ¦mpes sÃ¥ tidligt som muligt efter fremspiring.\n",
       "Problemet er, at den spirer over en meget lang periode, og derfor er det vanskeligt at dÃ¦kke af for fremspiring.\n",
       "\n",
       "------------\n",
       "\n",
       "Svampesygdomme > FOTO: SOFIE HÃSTRUP OLESEN, LANDBONORD\n",
       "Optimalt tidspunkt for bekÃ¦mpelse af vÃ¦selhale med Boxer og Mateno Duo.\n",
       "\n",
       "------------\n",
       "\n",
       "Ukrudt > BekÃ¦mpelse af vÃ¦selhale om efterÃ¥ret\n",
       "Det understreger, at kemisk bekÃ¦mpelse af vÃ¦selhale ikke kan stÃ¥ alene, men at bestanden skal bringes ned pÃ¥ et niveau, hvor de tilbagevÃ¦rende vÃ¦selhale efter kemisk bekÃ¦mpelse er fÃ¥ og uden betydning for fortsat opformering og spredning.\n",
       "\n",
       "------------\n",
       "\n",
       "Svampesygdomme > FOTO: SOFIE HÃSTRUP OLESEN, LANDBONORD\n",
       "TABEL 18.\n",
       "BekÃ¦mpelse af vÃ¦selhale i vinterhvede om efter- Ã¥ret.\n",
       "(E16) Vinterhvede Stadie VÃ¦selhale Kemi og udbring- ning, kr.\n",
       "pr.\n",
       "ha Oktober November Antal planter pr.\n",
       "m2 Antal planter pr.\n",
       "m2 Procent effekt 2021-22, 3 forsÃ¸g\n",
       "\n",
       "------------\n",
       "\n",
       "Ukrudt > BekÃ¦mpelse af vÃ¦selhale om efterÃ¥ret\n",
       "Der er udfÃ¸rt tre forsÃ¸g i vinterhvede med bekÃ¦mpelse af vÃ¦selhale med forskellige strategier med Boxer, Ma- teno Duo og Atlantis OD i henholdsvis stadie 10-11 og stadie 12.\n",
       "Behandlingerne ses i tabel 18.\n",
       "ForsÃ¸gene er udfÃ¸rt pÃ¥ arealer med en meget stor be- stand af vÃ¦selhale, i gennemsnit ca.\n",
       "600 planter pr.\n",
       "m2 ved optÃ¦lling i oktober.\n",
       "Den tidlige sprÃ¸jtning i stadie 10-11 er udfÃ¸rt fra 6 til 14 dage efter sÃ¥ning, som i gen- nemsnit har vÃ¦ret midt i september.\n",
       "Anden sprÃ¸jtning i ForsÃ¸gsled 2 og 6 viser, at der er opnÃ¥et samme effekt- niveau af 1,5 l Boxer pr.\n",
       "ha og 0,7 l Mateno Duo pr.\n",
       "ha.\n",
       "I forsÃ¸gsled 3 til 5 er forskellige blandingsforhold mel- lem Boxer og Mateno Duo afprÃ¸vet, hvilket samlet er en hÃ¸jere indsats.\n",
       "Effekten er dermed ogsÃ¥ lidt bedre.\n",
       "Re- sultatet viser ogsÃ¥ i disse forsÃ¸gsled, at der har vÃ¦ret et ligevÃ¦rdigt bidrag fra begge midler."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = collection.query(query_texts=[query], n_results=5)\n",
    "context = result[\"documents\"][0]\n",
    "#display(Markdown(f\"------------\\n\\n{\"\\n\\n------------\\n\\n\".join(context)}\"))\n",
    "\n",
    "formatted_text = \"\\n\\n------------\\n\\n\".join(context)\n",
    "\n",
    "# Display the formatted markdown\n",
    "display(Markdown(f\"{formatted_text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d72d4-9bc5-4841-8d9c-ac607e7c754b",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f57f936b-889a-4a9b-8e76-a588a0bfc9f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhvordan kan jeg bedst bekÃ¦mpe vÃ¦selhale?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant that answers questions about landsforsÃ¸gene using provided context. You must provide your answer in the Danish language.\u001b[39m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{query}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m message \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat(query\u001b[38;5;241m=\u001b[39mquery, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mcontext\u001b[49m))\n\u001b[1;32m     16\u001b[0m display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'context' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = PromptTemplate(\"\"\"You are a helpful assistant that answers questions about landsforsÃ¸gene using provided context. You must provide your answer in the Danish language.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Context: \n",
    "\n",
    "-----------------------------------\n",
    "{context}\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "\"\"\")\n",
    "message = prompt.format(query=query, context=\"\\n\\n\".join(context))\n",
    "display(Markdown(f\"{message}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f15b71f-dbeb-4138-9235-db6c453ffaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. SkadedyrsbekÃ¦mpelse: Hvis dit hjem er inficeret med vÃ¦selhale, kan du overveje at ansÃ¦tte en skadedyrsbekÃ¦mpelse specialist, der har vÃ¦rktÃ¸jer og erfaring med at eliminere denne type skadedyr.\n",
       "\n",
       "2. ReducÃ©r fugt: VÃ¦selhale trives i fugtige omgivelser. Du kan minimere fugt ved at reparere lÃ¦kager, anvende fugtighedsabsorberende produkter og holde dit hjem godt ventileret.\n",
       "\n",
       "3. StÃ¸vsug regelmÃ¦ssigt: VÃ¦selhale har tendens til at gemme sig i stÃ¸vede, mÃ¸rke omrÃ¥der. StÃ¸vsugning kan hjÃ¦lpe med at fjerne disse skjulesteder og eventuelle Ã¦g, de mÃ¥ have lagt.\n",
       "\n",
       "4. Anvend insekticider: Du kan ogsÃ¥ bruge insekticider designet til at bekÃ¦mpe vÃ¦selhale. Det er vigtigt at fÃ¸lge instruktionerne omhyggeligt for at undgÃ¥ at skade dit hjem eller din sundhed.\n",
       "\n",
       "5. Benyt fÃ¦lder: Giftfri limfÃ¦lder kan vÃ¦re effektive til at fange vÃ¦selhale. FÃ¦lderne kan placere pÃ¥ steder, hvor du har observeret vÃ¦selhale, sÃ¥som kÃ¸kkenet, badevÃ¦relset eller kÃ¦lderen.\n",
       "\n",
       "Husk at det altid er bedst at fÃ¥ professionel hjÃ¦lp, hvis du har problemer med skadedyr i dit hjem. En professionel skadedyrsspecialist kan give en mere permanent lÃ¸sning pÃ¥ problemet."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"hvordan kan jeg bedst bekÃ¦mpe vÃ¦selhale?\"\n",
    "\n",
    "stream = openai_client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    model=\"gpt4\",\n",
    "    stream=True)\n",
    "\n",
    "output = \"\"\n",
    "for chunk in stream:\n",
    "    if chunk.choices:  # Check if the list is not empty\n",
    "        output += chunk.choices[0].delta.content or \"\"\n",
    "    display(Markdown(f\"{output}\"), clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c16e9-8df3-4558-a3bd-303274ca657c",
   "metadata": {},
   "source": [
    "## Normal RAG example with llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba467d07-258a-4db8-a02d-68fae55e848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from chromadb import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ChromaDB Vector Store\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"./landsforsÃ¸g/data/baseline-rag/chromadb\", settings=Settings(allow_reset=True))\n",
    "chroma_client.reset()\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"landsforsoeg\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=\"gpt4\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embedding = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# Define the ingestion pipeline to add documents to vector store\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=20),\n",
    "        embedding,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "# Create index with the vector store and using the embedding model\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fb9e4b-a9ad-4da6-aaa5-82a17402c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 662 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Fetch documents\n",
    "documents = SimpleDirectoryReader('./landsforsÃ¸g').load_data()\n",
    "\n",
    "# Run pipeline\n",
    "pipeline.run(documents=documents)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f05231da-1fb9-48f8-b935-859d19e02140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import BaseSynthesizer\n",
    "\n",
    "    \n",
    "qa_prompt = PromptTemplate(\n",
    "    \"\"\"You are a helpful assistant that answers questions about the content of documents and provides detailed expert advice. \n",
    "    You must provide your answer in the Danish language.\n",
    "    If the answer contains multiple steps or points, provide the answer in a bullet format.\n",
    "    Below the answer, the source of the answer should be provided including file name and page number.\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query.\n",
    "    Query: {query_str}\n",
    "    Answer: \n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "class RAGQueryEngine(CustomQueryEngine):\n",
    "    \"\"\"RAG String Query Engine.\"\"\"\n",
    "\n",
    "    retriever: BaseRetriever\n",
    "    response_synthesizer: BaseSynthesizer\n",
    "    llm: OpenAI\n",
    "    qa_prompt: PromptTemplate\n",
    "\n",
    "    def custom_query(self, query_str: str):\n",
    "        nodes = self.retriever.retrieve(query_str)\n",
    "        context_str = \"\\n\\n\".join([n.node.get_content(metadata_mode=\"all\") for n in nodes])\n",
    "        #context = qa_prompt.format(\n",
    "        #    context_str=context_str, query_str=query_str)\n",
    "        response = self.llm.complete(\n",
    "            qa_prompt.format(context_str=context_str, query_str=query_str)\n",
    "        )\n",
    "                    \n",
    "        return str(response) + \"\\n\\n-------------------------\\n\\nKontekst:\\n\\n\" + context_str\n",
    "\n",
    "\n",
    "synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "query_engine = RAGQueryEngine(\n",
    "    retriever=index.as_retriever(),\n",
    "    response_synthesizer=synthesizer,\n",
    "    llm=llm,\n",
    "    qa_prompt=qa_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96f193f2-2f12-4b69-b306-f2fb3bc01b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "For at vÃ¦lge den bedste vÃ¥rbygsort, skal du overveje fÃ¸lgende faktorer:\n",
       "\n",
       "- VÃ¦lg en sort, der har givet et stort og stabilt udbytte i flere Ã¥rs forsÃ¸g.\n",
       "- VÃ¦lg en sort, der har lav modtagelighed over for sygdomme, i prioriteret rÃ¦kkefÃ¸lge: meldug, bygrust, skoldplet og bygbladplet.\n",
       "- VÃ¦lg en sort, der har resistens mod havrecystenematoder.\n",
       "- VÃ¦lg en sort, der har en god strÃ¥stivhed, sÃ¥ der ikke er behov for vÃ¦kstregulering.\n",
       "- VÃ¦lg en sort, der har en svag tendens til nedknÃ¦kning af aks og strÃ¥.\n",
       "- Hvis du dyrker vÃ¥rbyg til malt, skal du altid vÃ¦lge en maltbygsort, der er accepteret af handelspartneren.\n",
       "\n",
       "Kilde: planter_landsforsogene_2023.pdf, side 77 og planter_landsforsogene_2022.pdf, side 89.\n",
       "\n",
       "-------------------------\n",
       "\n",
       "Kontekst:\n",
       "\n",
       "page_label: 77\n",
       "file_name: planter_landsforsogene_2023.pdf\n",
       "file_path: /Users/peerchristensen/Desktop/Projects/advanced-rag-examples/landsforsÃ¸g/planter_landsforsogene_2023.pdf\n",
       "file_type: application/pdf\n",
       "file_size: 47095474\n",
       "creation_date: 2024-06-08\n",
       "last_modified_date: 2024-06-08\n",
       "\n",
       "Der var mange grÃ¸nskud i vÃ¥rbyg i 2023. Her er det en prÃ¸ve fra \n",
       "et forsÃ¸g med et vandindhold pÃ¥ over 30 procent.FOTO: LEIF HAGELSKJÃR, SEGES INNOVATION\n",
       "STRATEGI\n",
       "VÃ¦lg en vÃ¥rbygsort, der:\n",
       " >har givet et stort og stabilt udbytte i flere Ã¥rs for -\n",
       "sÃ¸g\n",
       " >har lav modtagelighed over for sygdommene (i \n",
       "prioriteret rÃ¦kkefÃ¸lge):\n",
       " â meldug\n",
       " â bygrust\n",
       " â skoldplet og bygbladplet\n",
       " >har resistens mod havrecystenematoder\n",
       " >har en god strÃ¥stivhed, sÃ¥ der ikke er behov for \n",
       "vÃ¦kstregulering\n",
       " >har en svag tendens til nedknÃ¦kning af aks og \n",
       "strÃ¥.\n",
       "Ved dyrkning af vÃ¥rbyg til malt bÃ¸r der altid vÃ¦lges \n",
       "en maltbygsort, der er accepteret af handelspart -\n",
       "neren.\n",
       "\n",
       "page_label: 89\n",
       "file_name: planter_landsforsogene_2022.pdf\n",
       "file_path: /Users/peerchristensen/Desktop/Projects/advanced-rag-examples/landsforsÃ¸g/planter_landsforsogene_2022.pdf\n",
       "file_type: application/pdf\n",
       "file_size: 53911931\n",
       "creation_date: 2024-06-07\n",
       "last_modified_date: 2024-06-07\n",
       "\n",
       "17. maj. ForsÃ¸get er sÃ¥et d. 21. marts.FOTO: LEIF HAGELSKJÃR, SEGES INNOVATION\n",
       "STRATEGI\n",
       "VÃ¦lg en vÃ¥rbygsort, der:\n",
       " >har givet et stort og stabilt udbytte i flere Ã¥rs for -\n",
       "sÃ¸g\n",
       " >har lav modtagelighed over for sygdommene (i \n",
       "prioriteret rÃ¦kkefÃ¸lge):\n",
       "â meldug\n",
       "â bygrust\n",
       "â skoldplet og bygbladplet\n",
       " >har resistens mod havrecystenematoder\n",
       " >har en god strÃ¥stivhed, sÃ¥ der ikke er behov for \n",
       "vÃ¦kstregulering\n",
       " >har en svag tendens til nedknÃ¦kning af aks og \n",
       "strÃ¥.\n",
       "Ved dyrkning af vÃ¥rbyg til malt bÃ¸r der altid vÃ¦lges \n",
       "en maltbygsort, der er accepteret af handelspart -\n",
       "neren."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "#query = \"hvem udgiver landsforsÃ¸gene?\"\n",
    "#query = \"hvordan kan jeg bedst bekÃ¦mpe vÃ¦selhale?\"\n",
    "query = \"hvordan vÃ¦lger jeg den bedste vÃ¥rbygsort?\"\n",
    "#query = \"hvad er reglerne for afstande ved etablering af husdyranlÃ¦g?\"\n",
    "#query = \"Beskriv MT-Klovvask\"\n",
    "response = query_engine.query(query)\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f4edc-00d2-4228-a34b-8296f30b0b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
